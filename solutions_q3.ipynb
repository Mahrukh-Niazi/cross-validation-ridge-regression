{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blond-hunger",
   "metadata": {},
   "source": [
    "# STA414: HW1 Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-uzbekistan",
   "metadata": {},
   "source": [
    "**Date**: February 8, 2021  \n",
    "**First Name**: Mahrukh  \n",
    "**Last Name**: Niazi  \n",
    "**Student Id**: 1003948204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8906a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05405dd",
   "metadata": {},
   "source": [
    "### Generate Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a940af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data and lambda values:\n",
    "data_train = {'X': np.genfromtxt('data_train_X.csv', delimiter=','),\n",
    "              't': np.genfromtxt('data_train_y.csv', delimiter=',')}\n",
    "data_test = {'X': np.genfromtxt('data_test_X.csv', delimiter=','),\n",
    "             't': np.genfromtxt('data_test_y.csv', delimiter=',')}\n",
    "\n",
    "lambda_seq = np.arange(0.02, 1.5, 0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-gnome",
   "metadata": {},
   "source": [
    "### Q3(a): Write the six functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-canvas",
   "metadata": {},
   "source": [
    "**Last function `cross_validation` demonstrates the correct order and arguments to do cross validation using the five other helper functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifth-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions:\n",
    "\n",
    "def shuffle_data(data: tuple) -> tuple:\n",
    "    \"\"\"This function takes data as an argument and returns its randomly \n",
    "    permutated version along the samples.\n",
    "    \n",
    "\n",
    "    Inputs:\n",
    "        - data: variable corresponding to the target vector (response) and \n",
    "                feature design matrix of the dataset, structured as a tuple.\n",
    "    \n",
    "    Outputs:\n",
    "        - reshuffled dataset, maintaining the target and feature pair as a\n",
    "          tuple of size two: the element at index 0 corresponds to the array\n",
    "          of target responses and the element at index 1 corresponds to the\n",
    "          array of feature matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    shuffled = {}\n",
    "    p = np.random.permutation(len(data['X']))\n",
    "    shuffled['X'], shuffled['t'] = data['X'][p], data['t'][p]\n",
    "\n",
    "    return shuffled\n",
    "\n",
    "def split_data(data: tuple, num_folds: int, fold: int) -> tuple:\n",
    "    \"\"\"This function takes data, number of partitions as num_folds, and the\n",
    "    selected partition fold as its arguments and returns the selected \n",
    "    partition fold as data_fold, and the remaining data as data_rest. It \n",
    "    splits the dataset (training data) into num_fold - 1 training sets and 1\n",
    "    validation set for a num_fold-cross validation algorithm. \n",
    "    \n",
    "    Inputs:\n",
    "        - data: variable corresponding to the target vector (response) and \n",
    "                feature design matrix of the dataset, structured as a tuple.\n",
    "        \n",
    "        - num_folds: integer corresponding to the k number of folds used for\n",
    "                     cross validation.\n",
    "        \n",
    "        - fold: integer corresponding to the selected fold for the validation\n",
    "                set.\n",
    "    Output:\n",
    "        - a tuple of size two: the element at index 0 corresponds to an\n",
    "          array consisting of the selected validation set data_fold, and the\n",
    "          element at index 1 corresponds to the array consisting of the \n",
    "          remaining folds for the training set data_rest for a num_folds \n",
    "          K-cross validation.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Calculates the size of each fold\n",
    "    sz_fold = int(len(data['t'])/num_folds)\n",
    "\n",
    "    # Calculates the limits of validation fold\n",
    "    idx_fold = list(range((fold-1)*sz_fold, fold*sz_fold-1))\n",
    "\n",
    "    # Calculates the difference of the two sets\n",
    "    idx_rest = list(set(range(0,len(data['t'])))-set(idx_fold))\n",
    "\n",
    "    # Assign the correct portions of each folder set\n",
    "    data_fold = {'X':data['X'][idx_fold,:],'t':data['t'][idx_fold]}\n",
    "    data_rest = {'X':data['X'][idx_rest,:],'t':data['t'][idx_rest]}\n",
    "\n",
    "    return(data_fold, data_rest)\n",
    "\n",
    "def train_model(data, lambd: float) -> np.ndarray:\n",
    "    \"\"\"This function takes data and lambd as arguments, and returns the \n",
    "    coefficients of ridge regression with penalty level lambda.\n",
    "    \n",
    "    Inputs:\n",
    "        - data: a tuple of size two, with element at index 0 corresponding to\n",
    "                an array of target responses and element at index 1 \n",
    "                corresponding to an array of feature matrix OR an array \n",
    "                corresponding to a specific fold from a pre-split k-fold cross \n",
    "                validation dataset. Data is assumed to be centered so no\n",
    "                intercept is included. \n",
    "                \n",
    "        - lambd: an integer for a specific lambda penalty value.\n",
    "        \n",
    "    Output:\n",
    "        - an array consisting of the coefficient estimates derived from a \n",
    "          ridge regression.\n",
    "\n",
    "    \"\"\"\n",
    "    xtx = np.matmul(np.transpose(data['X']), data['X'])\n",
    "    inverse = np.linalg.inv(xtx + lambd * np.identity(len(data['X'][0])))\n",
    "\n",
    "    return np.matmul(np.matmul(inverse, np.transpose(data['X'])), data['t'])\n",
    "   \n",
    "\n",
    "def predict(data, model: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"This function takes data and model as its arguments, and returns the\n",
    "    linear regression predicitons based on data and model.\n",
    "    \n",
    "    Inputs:\n",
    "        - data: a tuple of size two, with element at index 0 corresponding to\n",
    "                an array of target responses and element at index 1 \n",
    "                corresponding to an array of feature matrix OR an array \n",
    "                corresponding to a specific fold from a pre-split k-fold cross \n",
    "                validation dataset.\n",
    "        \n",
    "        - model: an array consisting of the coefficient estimates derived from \n",
    "                 a ridge regression.\n",
    "    \n",
    "    Outputs:\n",
    "        - an array consisting of the predictions derived from a linear ridge\n",
    "          regression.\n",
    "    \"\"\"\n",
    "    # predictions = np.matmul(data['X'],model)\n",
    "\n",
    "    return data['X'].dot(model)\n",
    "        \n",
    "def loss(data, model: np.ndarray) -> float:\n",
    "    \"\"\"This function takes data and model as its arguments and returns the \n",
    "    average squared error loss based on model. With the following variables\n",
    "    defined as: y = target response vector, X = feature design matrix,\n",
    "    \\beta = coefficients estimates vector, and n = sample size, the error loss\n",
    "    equation is given by MSE = (1/n) ((y - X\\beta)^2).\n",
    "    \n",
    "    Inputs:\n",
    "        - data: a tuple of size two, with element at index 0 corresponding to\n",
    "                an array of target responses and element at index 1 \n",
    "                corresponding to an array of feature matrix OR an array \n",
    "                corresponding to a specific fold from a pre-split k-fold cross \n",
    "                validation dataset.\n",
    "        \n",
    "        - model: an array consisting of the coefficient estimates derived from \n",
    "                 a ridge regression.\n",
    "    \n",
    "    Outputs:\n",
    "        - an array consisting of the MSE error derived from a linear ridge\n",
    "          regression on the validation set.\n",
    "\n",
    "    \"\"\"\n",
    "    # error = pow(np.linalg.norm(data['t']-np.matmul(data['X'],model)),2)/len(data['t'])\n",
    "\n",
    "    return np.sum((data['t'] - predict(data, model)) ** 2) / len(data['t'])\n",
    "\n",
    "def cross_validation(data: tuple, num_folds: int, lambd_seq: np.ndarray):\n",
    "    \"\"\"This function takes training data, number of folds num_folds, and a\n",
    "    sequence of lambdas lambd_seq as its arguments and returns the cross\n",
    "    validation error across all lambdas.\n",
    "\n",
    "    Inputs:\n",
    "        - data: variable corresponding to the target vector (response) and \n",
    "                feature design matrix of the training dataset, structured as a \n",
    "                tuple.\n",
    "                \n",
    "        - num_folds: integer corresponding to the k number of folds used for\n",
    "                     cross validation.\n",
    "        \n",
    "        - lambd_seq: a sequence of evenly spaced lambda values over a \n",
    "                     specified intereval.\n",
    "                     \n",
    "    Output:\n",
    "        - a list of cross validation errors across all specified lambda. \n",
    "          Length of list is the same as length of lambd_seq.\n",
    "\n",
    "    \"\"\"\n",
    "    data = shuffle_data(data)\n",
    "    cv_error = np.zeros(len(lambd_seq))\n",
    "\n",
    "    for i in range(len(lambd_seq)):\n",
    "        lambd = lambd_seq[i]\n",
    "        cv_loss_lmd = 0.0\n",
    "        for fold in range(num_folds):\n",
    "            val_cv, train_cv = split_data(data, num_folds, fold)\n",
    "            model = train_model(train_cv, lambd)\n",
    "            cv_loss_lmd += loss(val_cv, model)\n",
    "        cv_error[i] = (cv_loss_lmd / num_folds)\n",
    "        \n",
    "    return cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-potential",
   "metadata": {},
   "source": [
    "### Q3(b): Dataframe of Training and Test Errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forbidden-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training Error  Test Error  Lambda Values\n",
      "0         0.049736    5.106960           0.02\n",
      "1         0.105488    3.636285           0.05\n",
      "2         0.153355    3.075622           0.08\n",
      "3         0.196698    2.775597           0.11\n",
      "4         0.237064    2.591344           0.14\n",
      "5         0.275308    2.469397           0.17\n",
      "6         0.311942    2.384996           0.20\n",
      "7         0.347293    2.324998           0.23\n",
      "8         0.381581    2.281745           0.26\n",
      "9         0.414958    2.250458           0.29\n",
      "10        0.447532    2.227998           0.32\n",
      "11        0.479387    2.212213           0.35\n",
      "12        0.510584    2.201576           0.38\n",
      "13        0.541172    2.194978           0.41\n",
      "14        0.571190    2.191590           0.44\n",
      "15        0.600670    2.190781           0.47\n",
      "16        0.629639    2.192064           0.50\n",
      "17        0.658119    2.195055           0.53\n",
      "18        0.686132    2.199449           0.56\n",
      "19        0.713693    2.205002           0.59\n",
      "20        0.740819    2.211515           0.62\n",
      "21        0.767523    2.218824           0.65\n",
      "22        0.793818    2.226794           0.68\n",
      "23        0.819716    2.235314           0.71\n",
      "24        0.845228    2.244288           0.74\n",
      "25        0.870363    2.253640           0.77\n",
      "26        0.895131    2.263300           0.80\n",
      "27        0.919541    2.273214           0.83\n",
      "28        0.943601    2.283331           0.86\n",
      "29        0.967320    2.293612           0.89\n",
      "30        0.990705    2.304020           0.92\n",
      "31        1.013764    2.314524           0.95\n",
      "32        1.036504    2.325099           0.98\n",
      "33        1.058932    2.335722           1.01\n",
      "34        1.081053    2.346372           1.04\n",
      "35        1.102876    2.357033           1.07\n",
      "36        1.124405    2.367689           1.10\n",
      "37        1.145647    2.378328           1.13\n",
      "38        1.166607    2.388939           1.16\n",
      "39        1.187291    2.399512           1.19\n",
      "40        1.207705    2.410039           1.22\n",
      "41        1.227854    2.420511           1.25\n",
      "42        1.247743    2.430924           1.28\n",
      "43        1.267377    2.441271           1.31\n",
      "44        1.286760    2.451548           1.34\n",
      "45        1.305898    2.461750           1.37\n",
      "46        1.324796    2.471875           1.40\n",
      "47        1.343457    2.481919           1.43\n",
      "48        1.361887    2.491880           1.46\n",
      "49        1.380088    2.501756           1.49\n"
     ]
    }
   ],
   "source": [
    "def training_test_errors(trainData, testData, lambd_seq):\n",
    "    \"\"\"This function takes the training set trainData and test set testData and\n",
    "    returns the cross validation error across all lambdas for the adjusted model.\n",
    "    \n",
    "    Inputs:\n",
    "        - trainData: training set\n",
    "        \n",
    "        - testData: test set\n",
    "        \n",
    "        - lambd_seq: a sequence of evenly spaced lambda values over a \n",
    "                     specified intereval.\n",
    "    \n",
    "    Outputs:\n",
    "        - tuple of the training error and test error for each lambda\n",
    "        \n",
    "    \"\"\"\n",
    "    trainErrors = []\n",
    "    testErrors = []\n",
    "    \n",
    "    for i in range(len(lambd_seq)):\n",
    "        m = train_model(trainData, lambd_seq[i])\n",
    "        trainE = loss(trainData, m)\n",
    "        testE = loss(testData, m)\n",
    "        trainErrors.append(trainE)\n",
    "        testErrors.append(testE)\n",
    "        \n",
    "    return trainErrors, testErrors\n",
    "\n",
    "trainErr, testErr = training_test_errors(data_train, data_test, lambda_seq)\n",
    "\n",
    "from pandas import DataFrame\n",
    "errors_df = DataFrame(trainErr, columns = ['Training Error'])\n",
    "errors_df['Test Error'] = testErr\n",
    "errors_df['Lambda Values'] = np.arange(0.02, 1.5, 0.03)\n",
    "training_df = errors_df[['Lambda Values', 'Training Error', 'Test Error']]\n",
    "\n",
    "print(errors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-adaptation",
   "metadata": {},
   "source": [
    "### Q3(b): Dataframes of 5-fold and 10-fold CV Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animal-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Lambda Values  5-fold Cross Validation Error  \\\n",
      "0            0.02                       3.377419   \n",
      "1            0.05                       2.881441   \n",
      "2            0.08                       2.666061   \n",
      "3            0.11                       2.549610   \n",
      "4            0.14                       2.480733   \n",
      "5            0.17                       2.438578   \n",
      "6            0.20                       2.412914   \n",
      "7            0.23                       2.398082   \n",
      "8            0.26                       2.390689   \n",
      "9            0.29                       2.388572   \n",
      "10           0.32                       2.390290   \n",
      "11           0.35                       2.394845   \n",
      "12           0.38                       2.401529   \n",
      "13           0.41                       2.409823   \n",
      "14           0.44                       2.419344   \n",
      "15           0.47                       2.429801   \n",
      "16           0.50                       2.440972   \n",
      "17           0.53                       2.452683   \n",
      "18           0.56                       2.464800   \n",
      "19           0.59                       2.477215   \n",
      "20           0.62                       2.489843   \n",
      "21           0.65                       2.502616   \n",
      "22           0.68                       2.515479   \n",
      "23           0.71                       2.528387   \n",
      "24           0.74                       2.541304   \n",
      "25           0.77                       2.554200   \n",
      "26           0.80                       2.567052   \n",
      "27           0.83                       2.579839   \n",
      "28           0.86                       2.592547   \n",
      "29           0.89                       2.605162   \n",
      "30           0.92                       2.617673   \n",
      "31           0.95                       2.630073   \n",
      "32           0.98                       2.642354   \n",
      "33           1.01                       2.654511   \n",
      "34           1.04                       2.666540   \n",
      "35           1.07                       2.678438   \n",
      "36           1.10                       2.690203   \n",
      "37           1.13                       2.701832   \n",
      "38           1.16                       2.713325   \n",
      "39           1.19                       2.724682   \n",
      "40           1.22                       2.735902   \n",
      "41           1.25                       2.746985   \n",
      "42           1.28                       2.757933   \n",
      "43           1.31                       2.768745   \n",
      "44           1.34                       2.779423   \n",
      "45           1.37                       2.789968   \n",
      "46           1.40                       2.800381   \n",
      "47           1.43                       2.810664   \n",
      "48           1.46                       2.820818   \n",
      "49           1.49                       2.830844   \n",
      "\n",
      "    10-fold Cross Validation Error  \n",
      "0                         3.775382  \n",
      "1                         3.100881  \n",
      "2                         2.843977  \n",
      "3                         2.710989  \n",
      "4                         2.633997  \n",
      "5                         2.587450  \n",
      "6                         2.559298  \n",
      "7                         2.543046  \n",
      "8                         2.534863  \n",
      "9                         2.532343  \n",
      "10                        2.533898  \n",
      "11                        2.538442  \n",
      "12                        2.545207  \n",
      "13                        2.553637  \n",
      "14                        2.563325  \n",
      "15                        2.573961  \n",
      "16                        2.585311  \n",
      "17                        2.597195  \n",
      "18                        2.609473  \n",
      "19                        2.622032  \n",
      "20                        2.634786  \n",
      "21                        2.647664  \n",
      "22                        2.660611  \n",
      "23                        2.673582  \n",
      "24                        2.686540  \n",
      "25                        2.699457  \n",
      "26                        2.712308  \n",
      "27                        2.725074  \n",
      "28                        2.737741  \n",
      "29                        2.750296  \n",
      "30                        2.762729  \n",
      "31                        2.775032  \n",
      "32                        2.787200  \n",
      "33                        2.799227  \n",
      "34                        2.811111  \n",
      "35                        2.822849  \n",
      "36                        2.834439  \n",
      "37                        2.845880  \n",
      "38                        2.857172  \n",
      "39                        2.868315  \n",
      "40                        2.879310  \n",
      "41                        2.890157  \n",
      "42                        2.900858  \n",
      "43                        2.911413  \n",
      "44                        2.921824  \n",
      "45                        2.932094  \n",
      "46                        2.942223  \n",
      "47                        2.952214  \n",
      "48                        2.962068  \n",
      "49                        2.971788  \n"
     ]
    }
   ],
   "source": [
    "fiveFoldcv = cross_validation(data_train, 5, lambda_seq)\n",
    "tenFoldcv = cross_validation(data_train, 10, lambda_seq)\n",
    "\n",
    "cv_error = DataFrame(fiveFoldcv, columns = ['5-fold Cross Validation Error']) \n",
    "cv_error['10-fold Cross Validation Error'] = tenFoldcv\n",
    "cv_error['Lambda Values'] = np.arange(0.02, 1.5, 0.03)\n",
    "cv_error = cv_error[['Lambda Values', '5-fold Cross Validation Error', '10-fold Cross Validation Error']]\n",
    "print(cv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-fleet",
   "metadata": {},
   "source": [
    "### Q3(c): Plot of CV Error Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historical-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambda_seq, trainErr, label=\"Training Error\", color=\"black\")\n",
    "plt.plot(lambda_seq, testErr, label=\"Test Error\", color=\"purple\")\n",
    "plt.plot(lambda_seq, fiveFoldcv, label=\"5-fold CV Error\", color=\"blue\")\n",
    "plt.plot(lambda_seq, tenFoldcv, label=\"10-fold CV Error\", color=\"red\")\n",
    "\n",
    "plt.title(\"Cross Validation Curve Error\")\n",
    "plt.xlabel(\"Lambda Range\")\n",
    "plt.ylabel(\"MSE Error\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-conservation",
   "metadata": {},
   "source": [
    "Based on the plot, we can see that for the 5-fold, 10-fold, and Test data increasing lambda decreases error up to a point (minimum error) and then starts to increase as lambda increases. The minimum error for the 5-fold and 10-fold is close to that of the Test data, which suggests that using cross validation was good at finding a generalized parameter. \n",
    "\n",
    "On the other hand, the training error increases continuously. This is expected because when lambda equals 0 we get the non-penalized regression in which the MAP estimator coincides with the MLE estimator for the weight estimates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
